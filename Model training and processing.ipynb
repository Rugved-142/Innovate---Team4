{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca972a10-b157-4fe9-8a5c-53cd73d308bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded categories: [0 1 2 3 4 5 6 7 8]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Categories to encode\n",
    "CATEGORIES = [\"Cardboard\", \"Food Organics\", \"Glass\", \"Metal\", \"Miscellaneous Trash\", \"Paper\", \"Plastic\", \"Textile Trash\", \"Vegetation\"]\n",
    "\n",
    "\n",
    "# Create the LabelEncoder instance\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit the label encoder with the categories list\n",
    "label_encoder.fit(CATEGORIES)\n",
    "\n",
    "# Save the encoder to the same file\n",
    "file_path = 'label_encoder.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)\n",
    "\n",
    "# Print the encoding result to check\n",
    "print(\"Encoded categories:\", label_encoder.transform(categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9ddddea-8f43-4d3a-a27c-18dfe8da9930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes in the encoder: ['Cardboard' 'Food Organics' 'Glass' 'Metal' 'Miscellaneous Trash' 'Paper'\n",
      " 'Plastic' 'Textile Trash' 'Vegetation']\n",
      "Encoded label for 'Plastic': [6]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Path to your label_encoder.pkl file\n",
    "file_path = 'label_encoder.pkl'\n",
    "\n",
    "# Load the LabelEncoder from the file\n",
    "with open(file_path, 'rb') as file:\n",
    "    label_encoder = pickle.load(file)\n",
    "\n",
    "# Now you can use label_encoder to transform or inverse transform categories\n",
    "print(\"Classes in the encoder:\", label_encoder.classes_)\n",
    "\n",
    "# Example: Transforming a category to its encoded label\n",
    "encoded_label = label_encoder.transform([\"Plastic\"])\n",
    "print(\"Encoded label for 'Plastic':\", encoded_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98334d1-30aa-4dee-b1d9-6f5e5567ed8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plastic'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([6])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecd32568-f4dd-44cf-9f33-1436b24d67f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3803 images belonging to 9 classes.\n",
      "Found 949 images belonging to 9 classes.\n",
      "âŒ No GPU found, using CPU.\n",
      "Epoch 1/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 997ms/step - accuracy: 0.3269 - loss: 1.9260 - val_accuracy: 0.5490 - val_loss: 1.2751\n",
      "Epoch 2/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 981ms/step - accuracy: 0.6457 - loss: 1.0184 - val_accuracy: 0.5943 - val_loss: 1.1459\n",
      "Epoch 3/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 974ms/step - accuracy: 0.7132 - loss: 0.8278 - val_accuracy: 0.6080 - val_loss: 1.0850\n",
      "Epoch 4/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.7388 - loss: 0.7335 - val_accuracy: 0.6017 - val_loss: 1.0772\n",
      "Epoch 5/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 956ms/step - accuracy: 0.7819 - loss: 0.6435 - val_accuracy: 0.6238 - val_loss: 1.0444\n",
      "Epoch 6/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 983ms/step - accuracy: 0.7989 - loss: 0.5962 - val_accuracy: 0.6185 - val_loss: 1.0262\n",
      "Epoch 7/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 978ms/step - accuracy: 0.8187 - loss: 0.5427 - val_accuracy: 0.6365 - val_loss: 1.0065\n",
      "Epoch 8/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 988ms/step - accuracy: 0.8114 - loss: 0.5475 - val_accuracy: 0.6481 - val_loss: 0.9869\n",
      "Epoch 9/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 965ms/step - accuracy: 0.8526 - loss: 0.4759 - val_accuracy: 0.6575 - val_loss: 0.9815\n",
      "Epoch 10/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 980ms/step - accuracy: 0.8406 - loss: 0.4660 - val_accuracy: 0.6660 - val_loss: 0.9767\n",
      "Epoch 11/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 980ms/step - accuracy: 0.8588 - loss: 0.4134 - val_accuracy: 0.6449 - val_loss: 1.0050\n",
      "Epoch 12/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 986ms/step - accuracy: 0.8636 - loss: 0.4270 - val_accuracy: 0.6702 - val_loss: 0.9886\n",
      "Epoch 13/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 976ms/step - accuracy: 0.8621 - loss: 0.4140 - val_accuracy: 0.6628 - val_loss: 0.9718\n",
      "Epoch 14/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 1s/step - accuracy: 0.8777 - loss: 0.3821 - val_accuracy: 0.6628 - val_loss: 0.9560\n",
      "Epoch 15/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 968ms/step - accuracy: 0.8798 - loss: 0.3633 - val_accuracy: 0.6754 - val_loss: 0.9200\n",
      "Epoch 16/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 986ms/step - accuracy: 0.8912 - loss: 0.3394 - val_accuracy: 0.6818 - val_loss: 0.9215\n",
      "Epoch 17/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 1s/step - accuracy: 0.9010 - loss: 0.3163 - val_accuracy: 0.6691 - val_loss: 0.9313\n",
      "Epoch 18/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 1s/step - accuracy: 0.9053 - loss: 0.2966 - val_accuracy: 0.6776 - val_loss: 0.9412\n",
      "Epoch 19/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 992ms/step - accuracy: 0.9017 - loss: 0.2828 - val_accuracy: 0.6586 - val_loss: 0.9931\n",
      "Epoch 20/20\n",
      "\u001b[1m119/119\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 1s/step - accuracy: 0.9161 - loss: 0.2780 - val_accuracy: 0.6828 - val_loss: 0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… CNN Model Trained & Saved!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from flask import Flask, request, jsonify\n",
    "from PIL import Image\n",
    "\n",
    "# ============================\n",
    "# STEP 1: DATA PREPROCESSING\n",
    "# ============================\n",
    "DATASET_PATH = \"RealWaste\"  # Update dataset path\n",
    "\n",
    "# Ensure this matches the number of categories in your dataset\n",
    "CATEGORIES = [\"glass\", \"metal\", \"non_recyclable\", \"organic\", \"paper\", \"plastic\", \"uncertain\", \"category8\", \"category9\"]\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2,  # 80% Training, 20% Validation\n",
    "    rotation_range=20,\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2\n",
    ")\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "val_data = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# STEP 2: CNN MODEL DEFINITION\n",
    "# ============================\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the base model\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(CATEGORIES), activation='softmax')  # Output layer now matches CATEGORIES\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ============================\n",
    "# STEP 3: CHECKING GPU USAGE\n",
    "# ============================\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"ğŸ’ª Using GPU for training.\")\n",
    "else:\n",
    "    print(\"âŒ No GPU found, using CPU.\")\n",
    "\n",
    "# ============================\n",
    "# STEP 4: TRAIN THE CNN MODEL\n",
    "# ============================\n",
    "model.fit(train_data, epochs=20, validation_data=val_data, verbose=1)\n",
    "\n",
    "# Save Model\n",
    "model.save(\"waste_cnn_model.h5\")\n",
    "print(\"\\nâœ… CNN Model Trained & Saved!\")\n",
    "\n",
    "# ============================\n",
    "# STEP 5: FLASK API FOR PREDICTIONS\n",
    "# ============================\n",
    "# app = Flask(__name__)\n",
    "\n",
    "# Load Trained Model\n",
    "# cnn_model = tf.keras.models.load_model(\"waste_cnn_model.h5\")\n",
    "\n",
    "# @app.route('/predict_waste', methods=['POST'])\n",
    "# def predict_waste():\n",
    "#     file = request.files['file']\n",
    "#     img = Image.open(file).resize((224, 224))\n",
    "#     img_array = np.expand_dims(np.array(img) / 255.0, axis=0)\n",
    "\n",
    "#     predictions = cnn_model.predict(img_array)\n",
    "#     predicted_class = CATEGORIES[np.argmax(predictions)]\n",
    "\n",
    "#     return jsonify({\"Predicted Waste Category\": predicted_class})\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     print(\"\\nğŸš€ Starting Flask Server...\\n\")\n",
    "#     app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b408c66-1d24-4697-90e6-be46f526c2de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Image: RealWaste\\Textile Trash\\Textile Trash_283.jpg\n",
      "Predicted Category: Textile Trash\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Image: RealWaste\\Textile Trash\\Textile Trash_88.jpg\n",
      "Predicted Category: Miscellaneous Trash\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "Image: RealWaste\\Plastic\\Plastic_724.jpg\n",
      "Predicted Category: Plastic\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step\n",
      "Image: RealWaste\\Miscellaneous Trash\\Miscellaneous Trash_58.jpg\n",
      "Predicted Category: Miscellaneous Trash\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Image: RealWaste\\Plastic\\Plastic_6.jpg\n",
      "Predicted Category: Plastic\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n",
      "Image: RealWaste\\Food Organics\\Food Organics_102.jpg\n",
      "Predicted Category: Food Organics\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step\n",
      "Image: RealWaste\\Miscellaneous Trash\\Miscellaneous Trash_335.jpg\n",
      "Predicted Category: Miscellaneous Trash\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 142ms/step\n",
      "Image: RealWaste\\Vegetation\\Vegetation_373.jpg\n",
      "Predicted Category: Vegetation\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Image: RealWaste\\Vegetation\\Vegetation_136.jpg\n",
      "Predicted Category: Vegetation\n",
      "\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
      "Image: RealWaste\\Paper\\Paper_131.jpg\n",
      "Predicted Category: Paper\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import load_model\n",
    "from PIL import Image\n",
    "\n",
    "# ============================\n",
    "# STEP 6: TEST THE MODEL WITH 10 RANDOM SAMPLES\n",
    "# ============================\n",
    "\n",
    "# Load Trained Model\n",
    "model = load_model(\"waste_cnn_model.h5\")\n",
    "\n",
    "# Define categories again (for prediction purposes)\n",
    "CATEGORIES = [\"Cardboard\", \"Food Organics\", \"Glass\", \"Metal\", \"Miscellaneous Trash\", \"Paper\", \"Plastic\", \"Textile Trash\", \"Vegetation\"]\n",
    "\n",
    "# Dataset path (same as during training)\n",
    "DATASET_PATH = \"RealWaste\"\n",
    "\n",
    "# Function to load and preprocess the image\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = Image.open(img_path).resize((224, 224))  # Resize to the expected input size for MobileNetV2\n",
    "    img_array = np.array(img) / 255.0  # Rescale the image\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "    return img_array\n",
    "\n",
    "# List all images in the dataset directory (assuming each class is in its own subdirectory)\n",
    "image_paths = []\n",
    "for root, dirs, files in os.walk(DATASET_PATH):\n",
    "    for file in files:\n",
    "        if file.endswith(('.png', '.jpg', '.jpeg')):  # Check for image file types\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "\n",
    "# Pick 10 random images\n",
    "random_samples = random.sample(image_paths, 10)\n",
    "\n",
    "# Predict and display the results for 10 random samples\n",
    "for img_path in random_samples:\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "    \n",
    "    # Predict the category for the image\n",
    "    predictions = model.predict(img_array)\n",
    "    predicted_class = CATEGORIES[np.argmax(predictions)]\n",
    "    \n",
    "    print(f\"Image: {img_path}\")\n",
    "    print(f\"Predicted Category: {predicted_class}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "269c4519-670b-4201-b796-9e63867f997e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the mass of vegetation (kg):  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Step-by-Step Process for Converting Vegetation into Biogas ---\n",
      "1. Input Vegetation: 1000.0 kg\n",
      "2. Add Water: 1500.0 kg (to create a slurry with a 1:1.5 ratio)\n",
      "3. Add Inoculum: 250.0 kg (10% of total slurry)\n",
      "4. Total Slurry: 2500.0 kg (vegetation + water)\n",
      "5. Dry Matter in Vegetation: 800.0 kg (80% of vegetation)\n",
      "6. Biogas Yield: 240.0 mÂ³ (0.3 mÂ³ per kg of dry matter)\n",
      "7. Methane in Biogas: 144.0 mÂ³ (60% of biogas)\n",
      "8. Energy Content: 5155.2 MJ or 1432.1 kWh\n",
      "9. Biofuel Production: 144.0 liters of diesel equivalent\n"
     ]
    }
   ],
   "source": [
    "def biogas_conversion(mass_vegetation_kg):\n",
    "    # Constants\n",
    "    water_ratio = 1.5  # Water to vegetation ratio (1:1.5)\n",
    "    inoculum_ratio = 0.1  # Inoculum to total slurry ratio (10%)\n",
    "    biogas_yield = 0.3  # Biogas yield per kg of dry matter (mÂ³/kg)\n",
    "    dry_matter_content = 0.8  # Dry matter content in vegetation (80%)\n",
    "    methane_content = 0.6  # Methane content in biogas (60%)\n",
    "    methane_energy = 35.8  # Energy content of methane (MJ/mÂ³)\n",
    "\n",
    "    # Step 1: Calculate water and slurry\n",
    "    water_kg = mass_vegetation_kg * water_ratio\n",
    "    total_slurry_kg = mass_vegetation_kg + water_kg\n",
    "\n",
    "    # Step 2: Calculate inoculum\n",
    "    inoculum_kg = total_slurry_kg * inoculum_ratio\n",
    "\n",
    "    # Step 3: Calculate dry matter and biogas yield\n",
    "    dry_matter_kg = mass_vegetation_kg * dry_matter_content\n",
    "    biogas_volume_m3 = dry_matter_kg * biogas_yield\n",
    "\n",
    "    # Step 4: Calculate methane volume and energy content\n",
    "    methane_volume_m3 = biogas_volume_m3 * methane_content\n",
    "    energy_content_mj = methane_volume_m3 * methane_energy\n",
    "    energy_content_kwh = energy_content_mj * 0.2778  # Convert MJ to kWh\n",
    "\n",
    "    # Step 5: Calculate biofuel production (methane as biofuel)\n",
    "    biofuel_liters = methane_volume_m3  # 1 mÂ³ methane â‰ˆ 1 liter diesel equivalent\n",
    "\n",
    "    # Output the step-by-step process\n",
    "    print(\"\\n--- Step-by-Step Process for Converting Vegetation into Biogas ---\")\n",
    "    print(f\"1. Input Vegetation: {mass_vegetation_kg} kg\")\n",
    "    print(f\"2. Add Water: {water_kg} kg (to create a slurry with a 1:{water_ratio} ratio)\")\n",
    "    print(f\"3. Add Inoculum: {inoculum_kg:.1f} kg (10% of total slurry)\")\n",
    "    print(f\"4. Total Slurry: {total_slurry_kg:.1f} kg (vegetation + water)\")\n",
    "    print(f\"5. Dry Matter in Vegetation: {dry_matter_kg} kg (80% of vegetation)\")\n",
    "    print(f\"6. Biogas Yield: {biogas_volume_m3:.1f} mÂ³ (0.3 mÂ³ per kg of dry matter)\")\n",
    "    print(f\"7. Methane in Biogas: {methane_volume_m3:.1f} mÂ³ (60% of biogas)\")\n",
    "    print(f\"8. Energy Content: {energy_content_mj:.1f} MJ or {energy_content_kwh:.1f} kWh\")\n",
    "    print(f\"9. Biofuel Production: {biofuel_liters:.1f} liters of diesel equivalent\")\n",
    "\n",
    "    return {\n",
    "        \"water_kg\": water_kg,\n",
    "        \"inoculum_kg\": inoculum_kg,\n",
    "        \"total_slurry_kg\": total_slurry_kg,\n",
    "        \"dry_matter_kg\": dry_matter_kg,\n",
    "        \"biogas_volume_m3\": biogas_volume_m3,\n",
    "        \"methane_volume_m3\": methane_volume_m3,\n",
    "        \"energy_content_mj\": energy_content_mj,\n",
    "        \"energy_content_kwh\": energy_content_kwh,\n",
    "        \"biofuel_liters\": biofuel_liters,\n",
    "    }\n",
    "\n",
    "\n",
    "# User input\n",
    "mass_vegetation_kg = float(input(\"Enter the mass of vegetation (kg): \"))\n",
    "\n",
    "results = biogas_conversion(mass_vegetation_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9c89ce-d81d-47d4-b858-345a65b28619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)          â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">655,872</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)                   â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,617</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ mobilenetv2_1.00_224 (\u001b[38;5;33mFunctional\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1280\u001b[0m)          â”‚       \u001b[38;5;34m2,257,984\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             â”‚                             â”‚                 â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 â”‚         \u001b[38;5;34m655,872\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)                   â”‚           \u001b[38;5;34m4,617\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,918,475</span> (11.13 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,918,475\u001b[0m (11.13 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660,489</span> (2.52 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m660,489\u001b[0m (2.52 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d2cf62-aad1-4083-8dd0-19fc6057b335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the material type (paper/glass/plastic/cardboard/food organics):  paper\n",
      "Enter the mass of the material (kg):  1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Paper Processing ---\n",
      "1. Biogas Yield: 250.0 mÂ³ (anaerobic digestion, 25 days)\n",
      "2. Bioethanol Yield: 250.0 liters (fermentation, 6 days)\n"
     ]
    }
   ],
   "source": [
    "def process_material(material_type, mass_kg):\n",
    "    if material_type == \"paper\":\n",
    "        # Paper to Biogas or Bioethanol\n",
    "        biogas_yield = 0.25  # mÂ³ per kg\n",
    "        bioethanol_yield = 0.25  # liters per kg\n",
    "        digestion_time_days = 25  # days\n",
    "        fermentation_time_days = 6  # days\n",
    "\n",
    "        biogas_volume = mass_kg * biogas_yield\n",
    "        bioethanol_volume = mass_kg * bioethanol_yield\n",
    "\n",
    "        print(\"\\n--- Paper Processing ---\")\n",
    "        print(f\"1. Biogas Yield: {biogas_volume:.1f} mÂ³ (anaerobic digestion, {digestion_time_days} days)\")\n",
    "        print(f\"2. Bioethanol Yield: {bioethanol_volume:.1f} liters (fermentation, {fermentation_time_days} days)\")\n",
    "\n",
    "    elif material_type == \"glass\":\n",
    "        # Glass Recycling\n",
    "        recycling_time_days = 1.5  # days\n",
    "\n",
    "        print(\"\\n--- Glass Processing ---\")\n",
    "        print(f\"1. Glass can be recycled into new products.\")\n",
    "        print(f\"2. Processing Time: {recycling_time_days} days\")\n",
    "\n",
    "    elif material_type == \"plastic\":\n",
    "        # Plastic to Bio-oil or Syngas\n",
    "        biooil_yield = 0.65  # liters per kg\n",
    "        syngas_yield = 1.25  # mÂ³ per kg\n",
    "        pyrolysis_time_hours = 1.5  # hours\n",
    "        gasification_time_hours = 1.5  # hours\n",
    "\n",
    "        biooil_volume = mass_kg * biooil_yield\n",
    "        syngas_volume = mass_kg * syngas_yield\n",
    "\n",
    "        print(\"\\n--- Plastic Processing ---\")\n",
    "        print(f\"1. Bio-oil Yield: {biooil_volume:.1f} liters (pyrolysis, {pyrolysis_time_hours} hours)\")\n",
    "        print(f\"2. Syngas Yield: {syngas_volume:.1f} mÂ³ (gasification, {gasification_time_hours} hours)\")\n",
    "\n",
    "    elif material_type == \"cardboard\":\n",
    "        # Cardboard to Biogas or Bioethanol\n",
    "        biogas_yield = 0.25  # mÂ³ per kg\n",
    "        bioethanol_yield = 0.25  # liters per kg\n",
    "        digestion_time_days = 25  # days\n",
    "        fermentation_time_days = 6  # days\n",
    "\n",
    "        biogas_volume = mass_kg * biogas_yield\n",
    "        bioethanol_volume = mass_kg * bioethanol_yield\n",
    "\n",
    "        print(\"\\n--- Cardboard Processing ---\")\n",
    "        print(f\"1. Biogas Yield: {biogas_volume:.1f} mÂ³ (anaerobic digestion, {digestion_time_days} days)\")\n",
    "        print(f\"2. Bioethanol Yield: {bioethanol_volume:.1f} liters (fermentation, {fermentation_time_days} days)\")\n",
    "\n",
    "    elif material_type == \"food organics\":\n",
    "        # Food Organics to Biogas or Compost\n",
    "        biogas_yield = 0.4  # mÂ³ per kg\n",
    "        compost_yield = 0.6  # kg compost per kg food waste\n",
    "        digestion_time_days = 25  # days\n",
    "        composting_time_days = 45  # days\n",
    "\n",
    "        biogas_volume = mass_kg * biogas_yield\n",
    "        compost_volume = mass_kg * compost_yield\n",
    "\n",
    "        print(\"\\n--- Food Organics Processing ---\")\n",
    "        print(f\"1. Biogas Yield: {biogas_volume:.1f} mÂ³ (anaerobic digestion, {digestion_time_days} days)\")\n",
    "        print(f\"2. Compost Yield: {compost_volume:.1f} kg (composting, {composting_time_days} days)\")\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid material type. Please choose 'paper', 'glass', 'plastic', 'cardboard', or 'food organics'.\")\n",
    "\n",
    "\n",
    "# User input\n",
    "material_type = input(\"Enter the material type (paper/glass/plastic/cardboard/food organics): \").lower()\n",
    "mass_kg = float(input(\"Enter the mass of the material (kg): \"))\n",
    "\n",
    "# Perform calculations and display results\n",
    "process_material(material_type, mass_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54096d19-d2cf-4f35-bfbd-f04fd3a2a2b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
